{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example.\n",
        "\n",
        "###Probability Mass Function (PMF) and Probability Density Function (PDF) are two ways to describe the probability distribution of a random variable.\n",
        "\n",
        "# 1. PMF is used for discrete random variables. It gives the probability of each possible value that the random variable can take. It is defined as:\n",
        "\n",
        "        PMF(x) = P(X = x)\n",
        "\n",
        "         where X is the random variable and x is the value it takes.\n",
        "\n",
        "* For example, let's consider rolling a fair six-sided die. The random variable X can take values from 1 to 6. The PMF for this random variable can be calculated as follows:\n",
        "\n",
        "      PMF(1) = P(X = 1) = 1/6\n",
        "      PMF(2) = P(X = 2) = 1/6\n",
        "      PMF(3) = P(X = 3) = 1/6\n",
        "      PMF(4) = P(X = 4) = 1/6\n",
        "      PMF(5) = P(X = 5) = 1/6\n",
        "      PMF(6) = P(X = 6) = 1/6\n",
        "\n",
        "# 2. PDF is used for continuous random variables. It gives the probability density of the random variable at each point in its range. It is defined as:\n",
        "\n",
        "      PDF(x) = dF(x)/dx\n",
        "\n",
        "      where F(x) is the cumulative distribution function of the random variable.\n",
        "\n",
        "* For example, let's consider a random variable X that follows a normal distribution with mean 0 and standard deviation 1. The PDF for this random variable is given by:\n",
        "\n",
        "      PDF(x) = (1/sqrt(2*pi))*exp(-x^2/2)\n",
        "\n",
        "###where pi is the mathematical constant, exp is the exponential function, and sqrt is the square root function. This PDF can be used to calculate the probability of X taking a value in a certain interval. For example, the probability of X being between -1 and 1 is:\n",
        "\n",
        "       P(-1 < X < 1) = ∫-1^1 PDF(x) dx = 0.6827\n",
        "\n",
        "       where ∫ is the integration symbol."
      ],
      "metadata": {
        "id": "KTU0f3nLqFYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n",
        "\n",
        "* So, the CDF is a function that tells us the probability that a random variable X is less than or equal to a certain value x. For example, let's say we have a random variable X that follows a normal distribution with mean 0 and standard deviation 1. We can use the CDF to find the probability that X is less than or equal to 1. To do this, we would simply plug in x = 1 into the CDF equation, which is CDF(x) = P(X ≤ x). The resulting probability would tell us the likelihood of X being less than or equal to 1.\n",
        "\n",
        "* The reason the CDF is useful is that it allows us to quickly and easily calculate probabilities for different values of X, without having to integrate the PDF. Additionally, the CDF gives us information about the overall shape of the probability distribution, including its mean and variance. Finally, the CDF is commonly used in statistical inference to determine critical values and significance levels for a given level of confidence."
      ],
      "metadata": {
        "id": "cOnvn7vAOyBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution.\n",
        "\n",
        "\n",
        "###So, the normal distribution is a probability distribution that has a bell-shaped curve. It's often used as a model in situations where the data follows a pattern that is similar to the normal distribution. Some examples of situations where we might use the normal distribution as a model include:\n",
        "\n",
        "* Heights and weights of people: If we collect data on the heights and weights of a large number of people, we might find that the data follows a bell-shaped curve. We could then use the normal distribution to model this data.\n",
        "\n",
        "* Errors in measurement: When we conduct experiments or make measurements, there is often some amount of error. If we collect data on the magnitude of these errors, we might find that it follows a normal distribution. This would allow us to model the errors and account for them in our analyses.\n",
        "\n",
        "* Stock prices: Stock prices are influenced by many different factors, and the normal distribution can be used to model the distribution of these factors. For example, daily stock returns often follow a normal distribution.\n",
        "\n",
        "####The normal distribution is defined by two parameters: the mean (μ) and the standard deviation (σ). The mean determines the center of the distribution, and the standard deviation determines the spread or width of the distribution.\n",
        "\n",
        "* If we change the mean or the standard deviation, we can change the shape of the normal distribution. For example, if we increase the standard deviation, the bell curve becomes wider and flatter. If we decrease the standard deviation, the curve becomes narrower and taller.\n",
        "\n",
        "###Overall, the normal distribution is a useful tool for modeling many real-world phenomena, and understanding its parameters can help us understand the shape of the distribution and make predictions about future outcomes."
      ],
      "metadata": {
        "id": "_L5akB4KPkcf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution.\n",
        "\n",
        "####The Normal Distribution is a really important concept in statistics and probability theory. One reason it's so important is because it's used in the Central Limit Theorem, which helps us make inferences about populations based on samples. The Normal Distribution is also used in statistical inference, data analysis, and making predictions.\n",
        "\n",
        "###There are many real-life examples of situations where the Normal Distribution can be observed. \n",
        "\n",
        "* One example is the heights of people. If you measure the heights of a large group of people and plot them on a graph, you'll often see that the data follows a bell-shaped curve that looks like the Normal Distribution. The mean height of the group is the center of the distribution, and the standard deviation tells us how spread out the heights are.\n",
        "\n",
        "* Another example of the Normal Distribution in real life is IQ scores. IQ scores are standardized so that they follow the Normal Distribution, with a mean of 100 and a standard deviation of 15. This means that most people have an IQ score close to 100, and that the distribution of scores is bell-shaped.\n",
        "\n",
        "* Blood pressure is another example of a real-life situation where the Normal Distribution can be observed. Systolic blood pressure measurements for healthy adults follow the Normal Distribution, with a mean around 120 mmHg and a standard deviation around 10 mmHg. This means that most healthy adults have a systolic blood pressure measurement close to 120 mmHg, and that the distribution of measurements is bell-shaped.\n",
        "\n",
        "###Overall, the Normal Distribution is really important in statistics and has many applications in the real world. Understanding the Normal Distribution and its properties can help us make better decisions and predictions in a wide variety of situations."
      ],
      "metadata": {
        "id": "PHfc7WaOQYG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?\n",
        "\n",
        "\n",
        "* The Bernoulli Distribution is a discrete probability distribution that models the outcome of a single binary experiment. For example, if we flip a coin and define \"heads\" as a success and \"tails\" as a failure, then the Bernoulli Distribution would model this situation, where the outcome of a single coin flip is either a success or a failure. The Bernoulli Distribution has one parameter, which is the probability of success (p).\n",
        "\n",
        "* The Binomial Distribution, on the other hand, models the number of successes in a fixed number of independent Bernoulli trials. In other words, it tells us how many times a particular event will occur in a given number of trials. The Binomial Distribution is the sum of a certain number of independent and identically distributed Bernoulli random variables. The Binomial Distribution has two parameters: the number of trials (n) and the probability of success in each trial (p).\n",
        "\n",
        "* For example, if we flip a coin 10 times and want to know the probability of getting exactly 5 heads, we can use the Binomial Distribution. In this case, n=10 and p=0.5. We can then use the Binomial Distribution formula to calculate the probability of getting exactly 5 heads.\n",
        "\n",
        "###So, the main difference between the Bernoulli Distribution and the Binomial Distribution is that the Bernoulli Distribution models the outcome of a single binary experiment, while the Binomial Distribution models the number of successes in a fixed number of independent Bernoulli trials."
      ],
      "metadata": {
        "id": "wuAv9oNNRK5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations.\n",
        "#Ans:- \n",
        "###To find the probability that a randomly selected observation will be greater than 60, we need to use the standard normal distribution, which has a mean of 0 and a standard deviation of 1. \n",
        "\n",
        "###We can standardize the dataset with a mean of 50 and a standard deviation of 10 using the following formula:\n",
        "\n",
        "         z = (x - μ) / σ\n",
        "\n",
        "       where z is the standard score, x is the observed value, μ is the mean, and σ is the standard deviation.\n",
        "\n",
        "###In this case, we want to find the probability that x > 60. We can standardize 60 using the formula above:\n",
        "\n",
        "     z = (60 - 50) / 10 = 1\n",
        "\n",
        "* This means that 60 is one standard deviation above the mean of 50.\n",
        "\n",
        "* Using a standard normal distribution table, we can find the probability that z is greater than 1. The table shows the area under the standard normal distribution curve to the left of each z-score. Since we want the probability of z being greater than 1, we need to subtract the area to the left of 1 from 1.\n",
        "\n",
        "###The area to the left of 1 is 0.8413, so the area to the right of 1 is:\n",
        "\n",
        "        P(z > 1) = 1 - 0.8413 = 0.1587\n",
        "\n",
        "##This means that the probability of selecting a value from the dataset that is greater than 60 is 0.1587, or 15.87%."
      ],
      "metadata": {
        "id": "D9-zOQOOR3_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q7: Explain uniform Distribution with an example.\n",
        "\n",
        "* A uniform distribution is a type of probability distribution where every possible value within a given range is equally likely to occur. So basically, if you have a range of values and each value has the same chance of being picked, that's a uniform distribution. For example, if you have a fair six-sided die, each of the six numbers has an equal probability of being rolled, so that's a discrete uniform distribution.\n",
        "\n",
        "* Another example is a continuous uniform distribution where any number within a range has an equal probability of being chosen. Like, if you're picking a random number between 0 and 1, each value in that range has the same chance of being picked. So if you wanted to pick a number between 0.2 and 0.4, that's just as likely as picking a number between 0.4 and 0.6, or any other range within that interval.\n",
        "\n",
        "* Uniform distributions are important in statistics and other fields because they provide a way to model situations where each outcome is equally likely. They're also useful as a baseline for comparing other distributions or testing statistical hypotheses."
      ],
      "metadata": {
        "id": "3Fc5mgcxWgQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q8: What is the z score? State the importance of the z score.\n",
        "\n",
        "* The z-score is a statistical measure that helps us compare and standardize data points from different distributions. It tells us how many standard deviations a data point is away from the mean of the distribution. So if you have a data point and you want to know how far it is from the average, you can calculate the z-score.\n",
        "\n",
        "* The formula for calculating the z-score is z = (x - μ) / σ, where x is the data point, μ is the mean of the population, and σ is the standard deviation of the population. By using this formula, we can convert any data point to a standardized value, which allows us to compare it to other data points from different distributions.\n",
        "\n",
        "* The importance of the z-score is that it allows us to compare data that have different units of measurement and different scales of variability. For example, if you want to compare the heights of two groups of people, but one group is measured in feet and the other group is measured in centimeters, you can convert both groups to z-scores and then compare them. This is also useful in fields like finance, where you might want to compare the returns of two investments that have different levels of risk.\n",
        "\n",
        "###Overall, the z-score is a powerful statistical tool that helps us standardize and compare data from different distributions, making it an important concept in many fields, including science, business, and social science."
      ],
      "metadata": {
        "id": "9WQb71vdaSY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.\n",
        "\n",
        "* The Central Limit Theorem is a really important concept in statistics that tells us that if we take lots of random samples of the same size from any population, the distribution of the sample means will become approximately normal, even if the original population distribution is not normal.\n",
        "\n",
        "* So basically, if we keep taking more and more samples of the same size, the distribution of the means of those samples will start to look like a bell curve, with the mean of the sample means being the same as the population mean, and the standard deviation of the sample means being the population standard deviation divided by the square root of the sample size.\n",
        "\n",
        "* The Central Limit Theorem is significant because it allows us to make inferences about population parameters, such as the mean and standard deviation, based on a sample of observations. This means that we can estimate things like the average height or weight of a population with a high degree of accuracy, even if we don't have access to the entire population data.\n",
        "\n",
        "* The Central Limit Theorem is also really useful in hypothesis testing and confidence interval estimation, which are common statistical techniques that rely on assumptions about the normality of the sample means. It's used in a lot of different fields, like finance, engineering, and science, to help make predictions and decisions based on data.\n",
        "\n",
        "###Overall, the Central Limit Theorem is a really important concept in statistics that helps us understand the behavior of random variables and make inferences from data."
      ],
      "metadata": {
        "id": "aRsSeNMma1gU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q10 State the assumptions of the Central Limit Theorem.\n",
        "\n",
        "* The Central Limit Theorem is a really important concept in statistics, but it relies on a few assumptions to hold true. The first assumption is that the sample is drawn randomly from the population. This means that each observation in the sample is independent of the others, and that the sample is representative of the entire population.\n",
        "\n",
        "* The second assumption is that the sample size is large enough. In general, a sample size of 30 or more is considered large enough for the Central Limit Theorem to hold. This is because larger sample sizes tend to provide a more accurate estimate of the population mean and standard deviation.\n",
        "\n",
        "* The third assumption is that each observation in the sample is independent of the others. This means that the value of one observation does not affect the value of another observation in the sample.\n",
        "\n",
        "* The fourth assumption is that the population from which the sample is drawn is finite. This means that there is a limited number of observations in the population, and that the sample represents a subset of these observations.\n",
        "\n",
        "* The fifth assumption is that the population has a constant mean and variance. This means that the population mean and standard deviation do not change over time.\n",
        "\n",
        "* The final assumption is that the population is normally distributed. While the Central Limit Theorem does not require the population to be normally distributed, it does assume that the population is not too skewed or heavily-tailed. If these assumptions are met, then the Central Limit Theorem provides a powerful tool for making inferences about population parameters based on sample means."
      ],
      "metadata": {
        "id": "XTNQq3bHb3Nl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qahAa57_pwfW"
      },
      "outputs": [],
      "source": []
    }
  ]
}